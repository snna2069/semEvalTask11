{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13713128,"sourceType":"datasetVersion","datasetId":8723907}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:16.693788Z","iopub.execute_input":"2025-11-18T19:46:16.694079Z","iopub.status.idle":"2025-11-18T19:46:53.079233Z","shell.execute_reply.started":"2025-11-18T19:46:16.694056Z","shell.execute_reply":"2025-11-18T19:46:53.078523Z"}},"outputs":[{"name":"stderr","text":"2025-11-18 19:46:32.634829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763495192.827181      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763495192.882903      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"TRAIN_FILE = \"/kaggle/input/traindata/train_data.json\"\n\nwith open(TRAIN_FILE, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\ndf = pd.DataFrame(data)\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:53.080466Z","iopub.execute_input":"2025-11-18T19:46:53.081052Z","iopub.status.idle":"2025-11-18T19:46:53.125315Z","shell.execute_reply.started":"2025-11-18T19:46:53.081030Z","shell.execute_reply":"2025-11-18T19:46:53.124431Z"}},"outputs":[{"name":"stdout","text":"Shape: (960, 4)\nColumns: ['id', 'syllogism', 'validity', 'plausibility']\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  50146f21-d265-4e3a-8d93-8165cdbe89a3   \n1  dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a   \n2  e30b1f83-a4c3-49cb-8aaf-5f64208c625b   \n3  a30e07d5-0fb3-4097-9892-4b145b0c54f5   \n4  5b8161b7-b1bf-4e16-a854-cd52cdce8a1b   \n\n                                           syllogism  validity  plausibility  \n0  All cars are a type of vehicle. No animal is a...     False          True  \n1  Nothing that is a soda is a juice. A portion o...      True          True  \n2  Everything that is a planet is a celestial bod...     False         False  \n3  Every cat is an invisible creature. A number o...      True         False  \n4  There are no capital cities which are oceans. ...      True          True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>syllogism</th>\n      <th>validity</th>\n      <th>plausibility</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50146f21-d265-4e3a-8d93-8165cdbe89a3</td>\n      <td>All cars are a type of vehicle. No animal is a...</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a</td>\n      <td>Nothing that is a soda is a juice. A portion o...</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e30b1f83-a4c3-49cb-8aaf-5f64208c625b</td>\n      <td>Everything that is a planet is a celestial bod...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a30e07d5-0fb3-4097-9892-4b145b0c54f5</td>\n      <td>Every cat is an invisible creature. A number o...</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5b8161b7-b1bf-4e16-a854-cd52cdce8a1b</td>\n      <td>There are no capital cities which are oceans. ...</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def validity_to_int(x):\n    # handles True/False, \"True\"/\"False\", 0/1\n    if isinstance(x, bool):\n        return int(x)\n    if isinstance(x, str):\n        return 1 if x.lower() in [\"true\", \"1\", \"valid\"] else 0\n    return int(x)\n\ndf[\"label\"] = df[\"validity\"].apply(validity_to_int)\n\n# Keep only needed columns\ndf = df[[\"id\", \"syllogism\", \"label\"]].rename(columns={\"syllogism\": \"text\"})\n\n# VERY light cleaning: just collapse extra spaces\ndf[\"text\"] = df[\"text\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n\nprint(df[\"label\"].value_counts())\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:53.126066Z","iopub.execute_input":"2025-11-18T19:46:53.126284Z","iopub.status.idle":"2025-11-18T19:46:53.159997Z","shell.execute_reply.started":"2025-11-18T19:46:53.126268Z","shell.execute_reply":"2025-11-18T19:46:53.159239Z"}},"outputs":[{"name":"stdout","text":"label\n0    480\n1    480\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  50146f21-d265-4e3a-8d93-8165cdbe89a3   \n1  dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a   \n2  e30b1f83-a4c3-49cb-8aaf-5f64208c625b   \n3  a30e07d5-0fb3-4097-9892-4b145b0c54f5   \n4  5b8161b7-b1bf-4e16-a854-cd52cdce8a1b   \n\n                                                text  label  \n0  All cars are a type of vehicle. No animal is a...      0  \n1  Nothing that is a soda is a juice. A portion o...      1  \n2  Everything that is a planet is a celestial bod...      0  \n3  Every cat is an invisible creature. A number o...      1  \n4  There are no capital cities which are oceans. ...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50146f21-d265-4e3a-8d93-8165cdbe89a3</td>\n      <td>All cars are a type of vehicle. No animal is a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a</td>\n      <td>Nothing that is a soda is a juice. A portion o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e30b1f83-a4c3-49cb-8aaf-5f64208c625b</td>\n      <td>Everything that is a planet is a celestial bod...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a30e07d5-0fb3-4097-9892-4b145b0c54f5</td>\n      <td>Every cat is an invisible creature. A number o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5b8161b7-b1bf-4e16-a854-cd52cdce8a1b</td>\n      <td>There are no capital cities which are oceans. ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sklearn.utils import resample\n\nlabel_counts = df[\"label\"].value_counts(normalize=True)\nprint(\"Label ratios:\", label_counts.to_dict())\n\n# If one class > 15% more than the other, upsample minority\nif abs(label_counts.get(0, 0) - label_counts.get(1, 0)) > 0.15:\n    minority_label = df[\"label\"].value_counts().idxmin()\n    majority_label = df[\"label\"].value_counts().idxmax()\n\n    minority = df[df[\"label\"] == minority_label]\n    majority = df[df[\"label\"] == majority_label]\n\n    minority_upsampled = resample(\n        minority,\n        replace=True,\n        n_samples=len(majority),\n        random_state=SEED\n    )\n\n    df_balanced = pd.concat([majority, minority_upsampled], ignore_index=True)\n    df_balanced = df_balanced.sample(frac=1.0, random_state=SEED).reset_index(drop=True)  # shuffle\n\n    df = df_balanced\n    print(\"Rebalanced label counts:\", df[\"label\"].value_counts())\nelse:\n    print(\"No heavy imbalance detected; using original data.\")\n\nprint(\"Final dataset size:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:53.160726Z","iopub.execute_input":"2025-11-18T19:46:53.160982Z","iopub.status.idle":"2025-11-18T19:46:53.181603Z","shell.execute_reply.started":"2025-11-18T19:46:53.160957Z","shell.execute_reply":"2025-11-18T19:46:53.180904Z"}},"outputs":[{"name":"stdout","text":"Label ratios: {0: 0.5, 1: 0.5}\nNo heavy imbalance detected; using original data.\nFinal dataset size: 960\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_df, val_df = train_test_split(\n    df,\n    test_size=0.15,\n    random_state=SEED,\n    stratify=df[\"label\"]\n)\n\nprint(\"Train size:\", len(train_df))\nprint(\"Val size:\", len(val_df))\nprint(\"Train label ratios:\", train_df[\"label\"].value_counts(normalize=True).to_dict())\nprint(\"Val label ratios:\", val_df[\"label\"].value_counts(normalize=True).to_dict())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:53.183557Z","iopub.execute_input":"2025-11-18T19:46:53.183850Z","iopub.status.idle":"2025-11-18T19:46:53.211570Z","shell.execute_reply.started":"2025-11-18T19:46:53.183833Z","shell.execute_reply":"2025-11-18T19:46:53.210846Z"}},"outputs":[{"name":"stdout","text":"Train size: 816\nVal size: 144\nTrain label ratios: {0: 0.5, 1: 0.5}\nVal label ratios: {0: 0.5, 1: 0.5}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_dataset   = Dataset.from_pandas(val_df.reset_index(drop=True))\n\ntrain_dataset, val_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:53.212304Z","iopub.execute_input":"2025-11-18T19:46:53.212603Z","iopub.status.idle":"2025-11-18T19:46:53.247979Z","shell.execute_reply.started":"2025-11-18T19:46:53.212573Z","shell.execute_reply":"2025-11-18T19:46:53.247233Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['id', 'text', 'label'],\n     num_rows: 816\n }),\n Dataset({\n     features: ['id', 'text', 'label'],\n     num_rows: 144\n }))"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"MODEL_NAME = \"microsoft/mdeberta-v3-base\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize_fn(batch):\n    return tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        max_length=512,   # plenty for syllogisms\n    )\n\ntrain_tok = train_dataset.map(tokenize_fn, batched=True)\nval_tok   = val_dataset.map(tokenize_fn, batched=True)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nprint(\"Tokenization done.\")\ntrain_tok[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:53.248748Z","iopub.execute_input":"2025-11-18T19:46:53.248959Z","iopub.status.idle":"2025-11-18T19:46:56.856163Z","shell.execute_reply.started":"2025-11-18T19:46:53.248942Z","shell.execute_reply":"2025-11-18T19:46:56.855379Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92e2241d9e6f43b4890b74a4bde35c13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54bbfc7b6ad469db78cb5804eac0799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb23f4499f748c68b5f1978859fe5ad"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/816 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91e13e4dc3e24b43b7c7d6eb80931d6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de4479e41ee4fbda48f6c44d97947e0"}},"metadata":{}},{"name":"stdout","text":"Tokenization done.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'id': 'd58fd355-2a98-4501-ac04-058a05090a80',\n 'text': 'Anyone who is a president is a citizen. Every single person who is a senator is a citizen. This leads to the conclusion that there are some senators who are not citizens.',\n 'label': 0,\n 'input_ids': [1,\n  299,\n  38227,\n  1867,\n  340,\n  260,\n  263,\n  13244,\n  340,\n  260,\n  263,\n  260,\n  102208,\n  261,\n  39580,\n  6676,\n  2986,\n  1867,\n  340,\n  260,\n  263,\n  260,\n  120812,\n  340,\n  260,\n  263,\n  260,\n  102208,\n  261,\n  1495,\n  14867,\n  264,\n  289,\n  288,\n  260,\n  49667,\n  534,\n  2109,\n  419,\n  2156,\n  260,\n  120812,\n  264,\n  1867,\n  419,\n  777,\n  260,\n  87669,\n  261,\n  2],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1]}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,\n).to(device)\n\n# Explicit label mapping: 0=invalid, 1=valid\nmodel.config.id2label = {0: \"invalid\", 1: \"valid\"}\nmodel.config.label2id = {\"invalid\": 0, \"valid\": 1}\n\nprint(\"Model on:\", device)\nprint(\"id2label:\", model.config.id2label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:46:56.857030Z","iopub.execute_input":"2025-11-18T19:46:56.857845Z","iopub.status.idle":"2025-11-18T19:47:04.572613Z","shell.execute_reply.started":"2025-11-18T19:46:56.857813Z","shell.execute_reply":"2025-11-18T19:47:04.571562Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa1343b1d014e6aad2f9960bfa09dfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bb8634ac1fc491398244b61c418ece2"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model on: cuda\nid2label: {0: 'invalid', 1: 'valid'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"./validity_results\",\n    num_train_epochs=6,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    learning_rate=1e-5,\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    save_steps=9999999,   # effectively disables mid-training checkpoints\n    eval_steps=200,\n    do_eval=True,\n    report_to=\"none\",\n)\n\nprint(\"TrainingArguments ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:47:04.573525Z","iopub.execute_input":"2025-11-18T19:47:04.573869Z","iopub.status.idle":"2025-11-18T19:47:04.645910Z","shell.execute_reply.started":"2025-11-18T19:47:04.573838Z","shell.execute_reply":"2025-11-18T19:47:04.641480Z"}},"outputs":[{"name":"stdout","text":"TrainingArguments ready.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1  = f1_score(labels, preds, average=\"macro\")\n    return {\"accuracy\": acc, \"f1\": f1}\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_tok,\n    eval_dataset=val_tok,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Trainer ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:47:04.647275Z","iopub.execute_input":"2025-11-18T19:47:04.650893Z","iopub.status.idle":"2025-11-18T19:47:04.693245Z","shell.execute_reply.started":"2025-11-18T19:47:04.650845Z","shell.execute_reply":"2025-11-18T19:47:04.691922Z"}},"outputs":[{"name":"stdout","text":"Trainer ready.\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_48/2819239377.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_output = trainer.train()\nprint(\"\\nTraining finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:47:04.694187Z","iopub.execute_input":"2025-11-18T19:47:04.694607Z","iopub.status.idle":"2025-11-18T19:49:02.414436Z","shell.execute_reply.started":"2025-11-18T19:47:04.694548Z","shell.execute_reply":"2025-11-18T19:49:02.413529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='612' max='612' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [612/612 01:54, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.710600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.685100</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.599800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.586900</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.510800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.436700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.346700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.365400</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.274000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.266800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.247500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.214900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nTraining finished.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"eval_metrics = trainer.evaluate(val_tok)\nprint(\"Raw eval metrics:\", eval_metrics)\n\nval_true = val_df[\"label\"].tolist()\npred_logits = trainer.predict(val_tok).predictions\nval_preds = pred_logits.argmax(axis=1)\n\nacc = accuracy_score(val_true, val_preds)\nf1  = f1_score(val_true, val_preds, average=\"macro\")\n\nprint(f\"\\nFinal VALIDITY Accuracy: {acc:.4f}\")\nprint(f\"Final VALIDITY F1 (macro): {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:49:02.415515Z","iopub.execute_input":"2025-11-18T19:49:02.416112Z","iopub.status.idle":"2025-11-18T19:49:04.464126Z","shell.execute_reply.started":"2025-11-18T19:49:02.416075Z","shell.execute_reply":"2025-11-18T19:49:04.463045Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Raw eval metrics: {'eval_loss': 0.6078586578369141, 'eval_accuracy': 0.8055555555555556, 'eval_f1': 0.8054054054054054, 'eval_runtime': 0.9717, 'eval_samples_per_second': 148.187, 'eval_steps_per_second': 37.047, 'epoch': 6.0}\n\nFinal VALIDITY Accuracy: 0.8056\nFinal VALIDITY F1 (macro): 0.8054\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"VALIDITY_SAVE_DIR = \"./validity_deberta_finalversion\"\n\nmodel.save_pretrained(VALIDITY_SAVE_DIR)\ntokenizer.save_pretrained(VALIDITY_SAVE_DIR)\n\nprint(\"Validity model saved to:\", VALIDITY_SAVE_DIR)\nprint(\"Files:\", os.listdir(VALIDITY_SAVE_DIR))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T19:49:04.465413Z","iopub.execute_input":"2025-11-18T19:49:04.465798Z","iopub.status.idle":"2025-11-18T19:49:07.681341Z","shell.execute_reply.started":"2025-11-18T19:49:04.465766Z","shell.execute_reply":"2025-11-18T19:49:07.680528Z"}},"outputs":[{"name":"stdout","text":"Validity model saved to: ./validity_deberta_finalversion\nFiles: ['tokenizer_config.json', 'tokenizer.json', 'model.safetensors', 'special_tokens_map.json', 'config.json', 'added_tokens.json', 'spm.model']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}