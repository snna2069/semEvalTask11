{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13758452,"sourceType":"datasetVersion","datasetId":8755260}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n)\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:31:37.746655Z","iopub.execute_input":"2025-11-18T05:31:37.747261Z","iopub.status.idle":"2025-11-18T05:32:10.849926Z","shell.execute_reply.started":"2025-11-18T05:31:37.747236Z","shell.execute_reply":"2025-11-18T05:32:10.849089Z"}},"outputs":[{"name":"stderr","text":"2025-11-18 05:31:52.555963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763443912.726298      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763443912.774347      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"TRAIN_FILE = \"/kaggle/input/plausibilitytraindata/train_data.json\"\n\ndf = pd.read_json(TRAIN_FILE)\n\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", df.columns.tolist())\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:10.851045Z","iopub.execute_input":"2025-11-18T05:32:10.851647Z","iopub.status.idle":"2025-11-18T05:32:10.905092Z","shell.execute_reply.started":"2025-11-18T05:32:10.851627Z","shell.execute_reply":"2025-11-18T05:32:10.904505Z"}},"outputs":[{"name":"stdout","text":"Shape: (960, 4)\nColumns: ['id', 'syllogism', 'validity', 'plausibility']\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  50146f21-d265-4e3a-8d93-8165cdbe89a3   \n1  dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a   \n2  e30b1f83-a4c3-49cb-8aaf-5f64208c625b   \n3  a30e07d5-0fb3-4097-9892-4b145b0c54f5   \n4  5b8161b7-b1bf-4e16-a854-cd52cdce8a1b   \n\n                                           syllogism  validity  plausibility  \n0  All cars are a type of vehicle. No animal is a...     False          True  \n1  Nothing that is a soda is a juice. A portion o...      True          True  \n2  Everything that is a planet is a celestial bod...     False         False  \n3  Every cat is an invisible creature. A number o...      True         False  \n4  There are no capital cities which are oceans. ...      True          True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>syllogism</th>\n      <th>validity</th>\n      <th>plausibility</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50146f21-d265-4e3a-8d93-8165cdbe89a3</td>\n      <td>All cars are a type of vehicle. No animal is a...</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a</td>\n      <td>Nothing that is a soda is a juice. A portion o...</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e30b1f83-a4c3-49cb-8aaf-5f64208c625b</td>\n      <td>Everything that is a planet is a celestial bod...</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a30e07d5-0fb3-4097-9892-4b145b0c54f5</td>\n      <td>Every cat is an invisible creature. A number o...</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5b8161b7-b1bf-4e16-a854-cd52cdce8a1b</td>\n      <td>There are no capital cities which are oceans. ...</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def label_to_int(x):\n    if isinstance(x, bool):\n        return int(x)\n    if isinstance(x, str):\n        return 1 if x.lower() in [\"true\", \"1\", \"yes\"] else 0\n    return int(x)\n\ndf[\"label\"] = df[\"plausibility\"].apply(label_to_int)\n\n# Keep only useful columns\ndf = df[[\"id\", \"syllogism\", \"label\"]]\n\nprint(df[\"label\"].value_counts())\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:10.905852Z","iopub.execute_input":"2025-11-18T05:32:10.906061Z","iopub.status.idle":"2025-11-18T05:32:11.057015Z","shell.execute_reply.started":"2025-11-18T05:32:10.906044Z","shell.execute_reply":"2025-11-18T05:32:11.056375Z"}},"outputs":[{"name":"stdout","text":"label\n0    486\n1    474\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                     id  \\\n0  50146f21-d265-4e3a-8d93-8165cdbe89a3   \n1  dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a   \n2  e30b1f83-a4c3-49cb-8aaf-5f64208c625b   \n3  a30e07d5-0fb3-4097-9892-4b145b0c54f5   \n4  5b8161b7-b1bf-4e16-a854-cd52cdce8a1b   \n\n                                           syllogism  label  \n0  All cars are a type of vehicle. No animal is a...      1  \n1  Nothing that is a soda is a juice. A portion o...      1  \n2  Everything that is a planet is a celestial bod...      0  \n3  Every cat is an invisible creature. A number o...      0  \n4  There are no capital cities which are oceans. ...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>syllogism</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50146f21-d265-4e3a-8d93-8165cdbe89a3</td>\n      <td>All cars are a type of vehicle. No animal is a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dfafb4f6-4e1d-4cd5-aeb4-75d36aafdf1a</td>\n      <td>Nothing that is a soda is a juice. A portion o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e30b1f83-a4c3-49cb-8aaf-5f64208c625b</td>\n      <td>Everything that is a planet is a celestial bod...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a30e07d5-0fb3-4097-9892-4b145b0c54f5</td>\n      <td>Every cat is an invisible creature. A number o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5b8161b7-b1bf-4e16-a854-cd52cdce8a1b</td>\n      <td>There are no capital cities which are oceans. ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_df, val_df = train_test_split(\n    df,\n    test_size=0.15,\n    random_state=SEED,\n    stratify=df[\"label\"]\n)\n\nprint(\"Train size:\", len(train_df))\nprint(\"Validation size:\", len(val_df))\nprint(train_df[\"label\"].value_counts(normalize=True))\nprint(val_df[\"label\"].value_counts(normalize=True))\n\n# Convert to HuggingFace Datasets\ntrain_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_dataset   = Dataset.from_pandas(val_df.reset_index(drop=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:11.058751Z","iopub.execute_input":"2025-11-18T05:32:11.059207Z","iopub.status.idle":"2025-11-18T05:32:11.090030Z","shell.execute_reply.started":"2025-11-18T05:32:11.059179Z","shell.execute_reply":"2025-11-18T05:32:11.089404Z"}},"outputs":[{"name":"stdout","text":"Train size: 816\nValidation size: 144\nlabel\n0    0.506127\n1    0.493873\nName: proportion, dtype: float64\nlabel\n0    0.506944\n1    0.493056\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"MODEL_NAME = \"microsoft/mdeberta-v3-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize_function(batch):\n    return tokenizer(\n        batch[\"syllogism\"],\n        truncation=True,\n        max_length=512,  \n    )\n\n# Apply tokenization\ntrain_tokenized = train_dataset.map(tokenize_function, batched=True)\nval_tokenized   = val_dataset.map(tokenize_function, batched=True)\n\n# Dynamic padding for batches\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nprint(\"Tokenization complete.\")\ntrain_tokenized[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:11.090695Z","iopub.execute_input":"2025-11-18T05:32:11.090899Z","iopub.status.idle":"2025-11-18T05:32:14.505085Z","shell.execute_reply.started":"2025-11-18T05:32:11.090882Z","shell.execute_reply":"2025-11-18T05:32:14.504473Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc4254863bcb419da751b13a8a85c79a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45f6a2de341244aaaca37f7a6b6eaa86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"532297ea5a524bd9997ef6a931042fdb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/816 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c7459d2ae14fcf9f3b987d49ccbad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90cc18aba56b4badb4bdb2ef7d6cb97c"}},"metadata":{}},{"name":"stdout","text":"Tokenization complete.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'id': '1e6eb831-90f8-44bc-9af7-cf906db517a2',\n 'syllogism': 'Every single shark is an aquatic creature. A number of sharks are classified as fish. Consequently, it is the case that some fish are aquatic creatures.',\n 'label': 1,\n 'input_ids': [1,\n  39580,\n  6676,\n  260,\n  129205,\n  340,\n  462,\n  65478,\n  6863,\n  318,\n  180345,\n  261,\n  299,\n  4404,\n  305,\n  260,\n  129205,\n  264,\n  419,\n  151440,\n  528,\n  42092,\n  261,\n  372,\n  177793,\n  485,\n  262,\n  610,\n  340,\n  288,\n  4073,\n  534,\n  2156,\n  42092,\n  419,\n  65478,\n  6863,\n  34931,\n  19178,\n  261,\n  2],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1]}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=2,     # plausible (1) / implausible (0)\n).to(device)\n\nmodel.config.id2label = {0: \"implausible\", 1: \"plausible\"}\nmodel.config.label2id = {\"implausible\": 0, \"plausible\": 1}\n\nprint(\"Model loaded on:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:14.505812Z","iopub.execute_input":"2025-11-18T05:32:14.506014Z","iopub.status.idle":"2025-11-18T05:32:21.634090Z","shell.execute_reply.started":"2025-11-18T05:32:14.505994Z","shell.execute_reply":"2025-11-18T05:32:21.633106Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708fe87aeef74e6aa4795ae8ca392d74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118becb6f4284a6ea5bbcd003696e898"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded on: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./plausibility_deberta_model\",\n    num_train_epochs=7,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    warmup_ratio=0.1,\n    logging_steps=20,\n\n    save_steps=200,\n    eval_steps=200,\n    do_eval=True,\n\n    logging_dir=\"./logs\",\n    report_to=\"none\"\n)\n\nprint(\"TrainingArguments loaded successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:21.635490Z","iopub.execute_input":"2025-11-18T05:32:21.637158Z","iopub.status.idle":"2025-11-18T05:32:21.708932Z","shell.execute_reply.started":"2025-11-18T05:32:21.637109Z","shell.execute_reply":"2025-11-18T05:32:21.705020Z"}},"outputs":[{"name":"stdout","text":"TrainingArguments loaded successfully.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average=\"macro\")\n\n    return {\"accuracy\": acc, \"f1\": f1}\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized,\n    eval_dataset=val_tokenized,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nprint(\"Trainer created successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:21.709701Z","iopub.execute_input":"2025-11-18T05:32:21.710087Z","iopub.status.idle":"2025-11-18T05:32:21.777665Z","shell.execute_reply.started":"2025-11-18T05:32:21.710060Z","shell.execute_reply":"2025-11-18T05:32:21.775433Z"}},"outputs":[{"name":"stdout","text":"Trainer created successfully.\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_48/765162736.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_output = trainer.train()\n\nprint(\"\\n\\n=== Training Completed Successfully ===\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:32:21.778643Z","iopub.execute_input":"2025-11-18T05:32:21.778962Z","iopub.status.idle":"2025-11-18T05:34:21.183135Z","shell.execute_reply.started":"2025-11-18T05:32:21.778935Z","shell.execute_reply":"2025-11-18T05:34:21.182358Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='714' max='714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [714/714 01:57, Epoch 7/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.700700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.714800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.707000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.693600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.707400</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.697500</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.652200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.663200</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.662100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.646200</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.579900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.496700</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.575800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.623900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.561200</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.477300</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.387300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.459700</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.459100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.426300</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.350800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.316400</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.272100</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.261600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.235300</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.239300</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.213600</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.132700</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.207000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.246900</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.165000</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.100500</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.147500</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.139500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.132200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\n\n=== Training Completed Successfully ===\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"eval_metrics = trainer.evaluate(val_tokenized)\nprint(\"Validation Metrics:\", eval_metrics)\n\n# For a clearer breakdown\nval_text = val_df[\"syllogism\"].tolist()\nval_true = val_df[\"label\"].tolist()\n\n# Get predictions\npreds_logits = trainer.predict(val_tokenized).predictions\npreds = preds_logits.argmax(axis=1)\n\nacc = accuracy_score(val_true, preds)\nf1 = f1_score(val_true, preds, average=\"macro\")\n\nprint(f\"\\nFinal Plausibility Accuracy: {acc:.4f}\")\nprint(f\"Final Plausibility F1 (macro): {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:34:21.185295Z","iopub.execute_input":"2025-11-18T05:34:21.185559Z","iopub.status.idle":"2025-11-18T05:34:22.346922Z","shell.execute_reply.started":"2025-11-18T05:34:21.185533Z","shell.execute_reply":"2025-11-18T05:34:22.345945Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Validation Metrics: {'eval_loss': 0.8640713095664978, 'eval_accuracy': 0.7777777777777778, 'eval_f1': 0.7776061776061776, 'eval_runtime': 0.5369, 'eval_samples_per_second': 268.183, 'eval_steps_per_second': 33.523, 'epoch': 7.0}\n\nFinal Plausibility Accuracy: 0.7778\nFinal Plausibility F1 (macro): 0.7776\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"SAVE_DIR = \"./plausibility_deberta_final\"\n\nmodel.save_pretrained(SAVE_DIR)\n\ntokenizer.save_pretrained(SAVE_DIR)\n\nprint(\"Model saved to:\", SAVE_DIR)\nprint(\"Files:\", os.listdir(SAVE_DIR))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T05:36:43.083929Z","iopub.execute_input":"2025-11-18T05:36:43.084249Z","iopub.status.idle":"2025-11-18T05:36:45.807295Z","shell.execute_reply.started":"2025-11-18T05:36:43.084228Z","shell.execute_reply":"2025-11-18T05:36:45.806563Z"}},"outputs":[{"name":"stdout","text":"Model saved to: ./plausibility_deberta_final\nFiles: ['tokenizer_config.json', 'added_tokens.json', 'config.json', 'spm.model', 'tokenizer.json', 'special_tokens_map.json', 'model.safetensors']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}